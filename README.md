# 2024-06-27-Presentation-LLMs-Playing-Mixed-Strategy-Nash-Equilibrium-Games

Presentation given at the [2024 LINCS Annual Workshop](https://www.lincs.fr/2024-lincs-annual-workshop-with-its-scientific-committee/).

*The video recording of the presentation will be posted soon.*

The notebook presented can be found [here](https://github.com/alonsosilvaallende/2024-06-27-Presentation-LLMs-Playing-Mixed-Strategy-Nash-Equilibrium-Games/blob/main/Presentation.ipynb).

To run the notebook, install the `requirements.txt`:
```console
pip install -r requirements.txt
```

This presentation took place on June 27, 2024.

The **title** of this presentation is "Large Language Models Playing Mixed Strategy Nash Equilibrium Games".

The **abstract** of this presentation is:

> *Generative artificial intelligence (Generative AI), and in particular Large Language Models (LLMs) have gained significant popularity among researchers and industrial communities, paving the way for integrating LLMs in different domains, such as robotics, telecom, and healthcare. In this paper, we study the intersection of game theory and generative artificial intelligence, focusing on the capabilities of LLMs to find the Nash equilibrium in games with a mixed strategy Nash equilibrium and no pure strategy Nash equilibrium (that we denote mixed strategy Nash equilibrium games). The study reveals a significant enhancement in the performance of LLMs when they are equipped with the possibility to run code and are provided with a specific prompt to incentivize them to do so. However, our research also highlights the limitations of LLMs when the randomization strategy of the game is not easy to deduce. It is evident that while LLMs exhibit remarkable proficiency in well-known standard games, their performance dwindles when faced with slight modifications of the same games. This paper aims to contribute to the growing body of knowledge on the intersection of game theory and generative artificial intelligence while providing valuable insights into LLMs strengths and weaknesses. It also underscores the need for further research to overcome the limitations of LLMs, particularly in dealing with even slightly more complex scenarios, to harness their full potential.*
